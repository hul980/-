{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KZxtkCxO-LE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8L6EwDuPbB_"
   },
   "outputs": [],
   "source": [
    "# 영어 댓글 데이터 전처리\n",
    "data = pd.read_csv('/content/drive/Shareddrives/데청캠/웹툰 세계화/데이터 모음집/ew_2_comment.csv')\n",
    "\n",
    "#정규화\n",
    "data['adj_comment'] = data['best_comment'].str.replace(\"[^0-9a-zA-Z ]\",\"\").str.lower().str.replace('^ +', \"\")\n",
    "\n",
    "#앞에 TOP이라는 글씨 쓰인것들 제거\n",
    "for i in range(len(data['adj_comment'])):\n",
    "  if data['adj_comment'][i][:3] == 'top':\n",
    "    data['adj_comment'][i] = data['adj_comment'][i][3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a15pf4iKPcHu"
   },
   "outputs": [],
   "source": [
    "# 형태소 분석\n",
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oxrY6YldPdFW"
   },
   "outputs": [],
   "source": [
    "#sentiwordnet 감성분석\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "\n",
    "def swn_polarity(text):\n",
    "    # 감성 지수 초기화 \n",
    "    pos_sentiment = 0.0\n",
    "    neg_sentiment = 0.0\n",
    "    tokens_count = 0\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    raw_sentences = sent_tokenize(text)\n",
    "    # 분해된 문장별로 단어 토큰 -> 품사 태깅 후에 SentiSynset 생성 -> 감성 지수 합산 \n",
    "    for raw_sentence in raw_sentences:\n",
    "        # NTLK 기반의 품사 태깅 문장 추출  \n",
    "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n",
    "        for word , tag in tagged_sentence:\n",
    "            \n",
    "            # WordNet 기반 품사 태깅과 어근 추출\n",
    "            wn_tag = penn_to_wn(tag) # 품사 태깅\n",
    "            if wn_tag not in (wn.NOUN , wn.ADJ, wn.ADV):\n",
    "                continue                   \n",
    "            lemma = lemmatizer.lemmatize(word, pos=wn_tag) # 어근 추출\n",
    "            if not lemma:\n",
    "                continue\n",
    "            # 어근을 추출한 단어와 WordNet 기반 품사 태깅을 입력해 Synset 객체를 생성. \n",
    "            synsets = wn.synsets(lemma , pos=wn_tag)\n",
    "            if not synsets:\n",
    "                continue\n",
    "            # sentiwordnet의 감성 단어 분석으로 감성 synset 추출\n",
    "            synset = synsets[0] \n",
    "            swn_synset = swn.senti_synset(synset.name()) # 사전속 해당 synset\n",
    "            pos_sentiment+= swn_synset.pos_score()\n",
    "            neg_sentiment+=swn_synset.neg_score()      \n",
    "            tokens_count += 1\n",
    "    \n",
    "    if not tokens_count:\n",
    "        return (0,0)\n",
    "    return (pos_sentiment,neg_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GszUHjKMPeO4"
   },
   "outputs": [],
   "source": [
    "score = []\n",
    "for i in data['best_comment']:\n",
    "    score.append(swn_polarity(i))\n",
    "total_data = pd.concat([data,result_score],axis=1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "영어 sentiword 감성분석.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
